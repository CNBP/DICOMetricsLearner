{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": ["'''\nThis script perfoms the basic process for applying a machine learning\nalgorithm to a dataset using Python libraries.\n\nThe four steps are:\n   1. Download a dataset (using pandas)\n   2. Process the numeric data (using numpy)\n   3. Train and evaluate learners (using scikit-learn)\n   4. Plot and compare results (using matplotlib)\n\n\nThe data is downloaded from URL, which is defined below. As is normal\nfor machine learning problems, the nature of the source data affects\nthe entire solution. When you change URL to refer to your own data, you\nwill need to review the data processing steps to ensure they remain\ncorrect.\n\n============\nExample Data\n============\nThe example is from http://mlr.cs.umass.edu/ml/datasets/Spambase\nIt contains pre-processed metrics, such as the frequency of certain\nwords and letters, from a collection of emails. A classification for\neach one indicating 'spam' or 'not spam' is in the final column.\nSee the linked page for full details of the data set.\n\nThis script uses three classifiers to predict the class of an email\nbased on the metrics. These are not representative of modern spam\ndetection systems.\n'''\n\n# Remember to update the script for the new data when you change this URL\nURL = \"http://mlr.cs.umass.edu/ml/machine-learning-databases/spambase/spambase.data\"\n\n# Uncomment this call when using matplotlib to generate images\n# rather than displaying interactive UI.\n#import matplotlib\n#matplotlib.use('Agg')\n\nfrom pandas import read_table\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ntry:\n    # [OPTIONAL] Seaborn makes plots nicer\n    import seaborn\nexcept ImportError:\n    pass\n\n# =====================================================================\n\ndef download_data():\n    '''\n    Downloads the data for this script into a pandas DataFrame.\n    '''\n\n    # If your data is in an Excel file, install 'xlrd' and use\n    # pandas.read_excel instead of read_table\n    #from pandas import read_excel\n    #frame = read_excel(URL)\n\n    # If your data is in a private Azure blob, install 'azure-storage' and use\n    # BlockBlobService.get_blob_to_path() with read_table() or read_excel()\n    #from azure.storage.blob import BlockBlobService\n    #service = BlockBlobService(ACCOUNT_NAME, ACCOUNT_KEY)\n    #service.get_blob_to_path(container_name, blob_name, 'my_data.csv')\n    #frame = read_table('my_data.csv', ...\n\n    frame = read_table(\n        URL,\n        \n        # Uncomment if the file needs to be decompressed\n        #compression='gzip',\n        #compression='bz2',\n\n        # Specify the file encoding\n        # Latin-1 is common for data from US sources\n        encoding='latin-1',\n        #encoding='utf-8',  # UTF-8 is also common\n\n        # Specify the separator in the data\n        sep=',',            # comma separated values\n        #sep='\\t',          # tab separated values\n        #sep=' ',           # space separated values\n\n        # Ignore spaces after the separator\n        skipinitialspace=True,\n\n        # Generate row labels from each row number\n        index_col=None,\n        #index_col=0,       # use the first column as row labels\n        #index_col=-1,      # use the last column as row labels\n\n        # Generate column headers row from each column number\n        header=None,\n        #header=0,          # use the first line as headers\n\n        # Use manual headers and skip the first row in the file\n        #header=0,\n        #names=['col1', 'col2', ...],\n    )\n\n    # Return a subset of the columns\n    #return frame[['col1', 'col4', ...]]\n\n    # Return the entire frame\n    return frame\n\n\n# =====================================================================\n\n\ndef get_features_and_labels(frame):\n    '''\n    Transforms and scales the input data and returns numpy arrays for\n    training and testing inputs and targets.\n    '''\n\n    # Replace missing values with 0.0, or we can use\n    # scikit-learn to calculate missing values (below)\n    #frame[frame.isnull()] = 0.0\n\n    # Convert values to floats\n    arr = np.array(frame, dtype=np.float)\n\n    # Use the last column as the target value\n    X, y = arr[:, :-1], arr[:, -1]\n    # To use the first column instead, change the index value\n    #X, y = arr[:, 1:], arr[:, 0]\n    \n    # Use 80% of the data for training; test against the rest\n    from sklearn.model_selection import train_test_split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n    # sklearn.pipeline.make_pipeline could also be used to chain \n    # processing and classification into a black box, but here we do\n    # them separately.\n    \n    # If values are missing we could impute them from the training data\n    #from sklearn.preprocessing import Imputer\n    #imputer = Imputer(strategy='mean')\n    #imputer.fit(X_train)\n    #X_train = imputer.transform(X_train)\n    #X_test = imputer.transform(X_test)\n    \n    # Normalize the attribute values to mean=0 and variance=1\n    from sklearn.preprocessing import StandardScaler\n    scaler = StandardScaler()\n    # To scale to a specified range, use MinMaxScaler\n    #from sklearn.preprocessing import MinMaxScaler\n    #scaler = MinMaxScaler(feature_range=(0, 1))\n    \n    # Fit the scaler based on the training data, then apply the same\n    # scaling to both training and test sets.\n    scaler.fit(X_train)\n    X_train = scaler.transform(X_train)\n    X_test = scaler.transform(X_test)\n\n    # Return the training and test sets\n    return X_train, X_test, y_train, y_test\n\n\n# =====================================================================\n\n\ndef evaluate_classifier(X_train, X_test, y_train, y_test):\n    '''\n    Run multiple times with different classifiers to get an idea of the\n    relative performance of each configuration.\n\n    Returns a sequence of tuples containing:\n        (title, precision, recall)\n    for each learner.\n    '''\n\n    # Import some classifiers to test\n    from sklearn.svm import LinearSVC, NuSVC\n    from sklearn.ensemble import AdaBoostClassifier\n\n    # We will calculate the P-R curve for each classifier\n    from sklearn.metrics import precision_recall_curve, f1_score\n    \n    # Here we create classifiers with default parameters. These need\n    # to be adjusted to obtain optimal performance on your data set.\n    \n    # Test the linear support vector classifier\n    classifier = LinearSVC(C=1)\n    # Fit the classifier\n    classifier.fit(X_train, y_train)\n    score = f1_score(y_test, classifier.predict(X_test))\n    # Generate the P-R curve\n    y_prob = classifier.decision_function(X_test)\n    precision, recall, _ = precision_recall_curve(y_test, y_prob)\n    # Include the score in the title\n    yield 'Linear SVC (F1 score={:.3f})'.format(score), precision, recall\n\n    # Test the Nu support vector classifier\n    classifier = NuSVC(kernel='rbf', nu=0.5, gamma=1e-3)\n    # Fit the classifier\n    classifier.fit(X_train, y_train)\n    score = f1_score(y_test, classifier.predict(X_test))\n    # Generate the P-R curve\n    y_prob = classifier.decision_function(X_test)\n    precision, recall, _ = precision_recall_curve(y_test, y_prob)\n    # Include the score in the title\n    yield 'NuSVC (F1 score={:.3f})'.format(score), precision, recall\n\n    # Test the Ada boost classifier\n    classifier = AdaBoostClassifier(n_estimators=50, learning_rate=1.0, algorithm='SAMME.R')\n    # Fit the classifier\n    classifier.fit(X_train, y_train)\n    score = f1_score(y_test, classifier.predict(X_test))\n    # Generate the P-R curve\n    y_prob = classifier.decision_function(X_test)\n    precision, recall, _ = precision_recall_curve(y_test, y_prob)\n    # Include the score in the title\n    yield 'Ada Boost (F1 score={:.3f})'.format(score), precision, recall\n\n# =====================================================================\n\n\ndef plot(results):\n    '''\n    Create a plot comparing multiple learners.\n\n    `results` is a list of tuples containing:\n        (title, precision, recall)\n    \n    All the elements in results will be plotted.\n    '''\n\n    # Plot the precision-recall curves\n\n    fig = plt.figure(figsize=(6, 6))\n    fig.canvas.set_window_title('Classifying data from ' + URL)\n\n    for label, precision, recall in results:\n        plt.plot(recall, precision, label=label)\n\n    plt.title('Precision-Recall Curves')\n    plt.xlabel('Precision')\n    plt.ylabel('Recall')\n    plt.legend(loc='lower left')\n\n    # Let matplotlib improve the layout\n    plt.tight_layout()\n\n    # ==================================\n    # Display the plot in interactive UI\n    plt.show()\n\n    # To save the plot to an image file, use savefig()\n    #plt.savefig('plot.png')\n\n    # Open the image file with the default image viewer\n    #import subprocess\n    #subprocess.Popen('plot.png', shell=True)\n\n    # To save the plot to an image in memory, use BytesIO and savefig()\n    # This can then be written to any stream-like object, such as a\n    # file or HTTP response.\n    #from io import BytesIO\n    #img_stream = BytesIO()\n    #plt.savefig(img_stream, fmt='png')\n    #img_bytes = img_stream.getvalue()\n    #print('Image is {} bytes - {!r}'.format(len(img_bytes), img_bytes[:8] + b'...'))\n\n    # Closing the figure allows matplotlib to release the memory used.\n    plt.close()\n\n\n# =====================================================================\n\n\nif __name__ == '__main__':\n    # Download the data set from URL\n    print(\"Downloading data from {}\".format(URL))\n    frame = download_data()\n\n    # Process data into feature and label arrays\n    print(\"Processing {} samples with {} attributes\".format(len(frame.index), len(frame.columns)))\n    X_train, X_test, y_train, y_test = get_features_and_labels(frame)\n\n    # Evaluate multiple classifiers on the data\n    print(\"Evaluating classifiers\")\n    results = list(evaluate_classifier(X_train, X_test, y_train, y_test))\n\n    # Display the results\n    print(\"Plotting the results\")\n    plot(results)\n"]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}